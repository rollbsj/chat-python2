from html import escape
import requests
from bs4 import BeautifulSoup


job_list = [] # job_list ì´ˆê¸°í™”ëŠ” ì „ì—­ìœ¼ë¡œ ì´ë™
def search_incruit(keyword, num_pages=1): # page ì¸ì ì´ë¦„ ë³€ê²½, ê¸°ë³¸ê°’ 1
    for i in range(num_pages): # num_pages ë§Œí¼ ë°˜ë³µ
        # incruit í˜ì´ì§€ë„¤ì´ì…˜ì€ no={í˜ì´ì§€ ë²ˆí˜¸} í˜•íƒœë¡œ ê°€ì •í•©ë‹ˆë‹¤.
        # í•œ í˜ì´ì§€ë‹¹ 30ê°œ í•­ëª©ì´ ìˆë‹¤ê³  ê°€ì •í•˜ê³  offsetì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        page = i * 30
        response = requests.get(f"https://search.incruit.com/list/search.asp?col=job&kw={keyword}&starno={page}")
        # print(f"https://search.incruit.com/list/search.asp?col=job&kw={keyword}&no={page_offset}")
        # print(response.text)

        soup = BeautifulSoup(response.text, "html.parser")

        lis=soup.find_all("li", class_="c_col")

        if not lis: # ë” ì´ìƒ ê³µê³ ê°€ ì—†ìœ¼ë©´ ë°˜ë³µ ì¤‘ë‹¨
            break

        for li in lis:
            company=li.find("a", class_="cpname").text
            title=li.find("div",class_="cl_top").find("a").text
            location = li.find("div",class_="cl_md").find_all("span")[0].text
            link = li.find("div", class_="cl_top").find("a").get("href")

            job_data = {
                    "íšŒì‚¬ì´ë¦„": company,
                    "ê³µê³ ì œëª©" : title,
                    "íšŒì‚¬ì¥ì†Œ": location,
                    "ìì„¸íˆë³´ê¸°": link
                }

            job_list.append(job_data) # ë“¤ì—¬ì“°ê¸° ìˆ˜ì •

    # ğŸ”¹ ì „ì²´ ì¶œë ¥
    print(f"ì´ {len(job_list)}ê°œ ê³µê³  ìˆ˜ì§‘")
    for job in job_list:
        print(job)

    return job_list

job_list = search_incruit("íŒŒì´ì¬",3) # num_pages ì¸ì ì¶”ê°€

import csv  

with open("jobs.csv","w",newline="",encoding="cp949") as file:
    writer = csv.writer(file)

    writer.writerow(["íšŒì‚¬ì´ë¦„", "ê³µê³ ì œëª©", "íšŒì‚¬ì¥ì†Œ", "ìì„¸íˆë³´ê¸°"])

    for job in job_list:
        writer.writerow([job["íšŒì‚¬ì´ë¦„"],job["ê³µê³ ì œëª©"],job["íšŒì‚¬ì¥ì†Œ"],job["ìì„¸íˆë³´ê¸°"]])
        